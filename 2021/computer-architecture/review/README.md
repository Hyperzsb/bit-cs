# 计算机体系结构复习提纲

## 计算机体系结构的基本概念

### 计算机系统的多层次结构

- 计算机系统的多层次结构： 
  - <u>第0级：硬级联逻辑级（硬联级）；由门、触发器等逻辑电路组成</u>
  - <u>第1级：微程序级；这级的机器语言是微指令集，用微指令编写的微程序一般是直接由硬件执行的</u>
  - <u>第2级：传统机器级；这级的机器语言是该机器的指令集，用机器指令编写的程序可以由微程序进行解释</u>
  - <u>第3级：操作系统级；直接接管传统机器中的硬件资源，也是传统机器的延伸</u>
  - <u>第4级：汇编语言级；这级的机器语言是汇编语言。完成汇编语言翻译的程序叫做汇编程序</u>
  - <u>第5级：高级语言级；这级的机器语言是各种高级语言，通常用编译程序来完成高级语言翻译的工作</u>
  - <u>第6级：应用语言级；这一级是为了使计算机满足某种用途而专门设计的，这一级的语言就是各种面向问题的应用语言</u>
- 固件（Firmware）：是一种具有软件功能的硬件
- 虚拟计算机：是指这个计算机只对该级的观察者存在
- 翻译（Translation）和解释（Interpretation）：
  - <u>翻译：是先用转换程序将高一级上的程序整个地变换成低一级机器上可运行的等效程序，然后再在低一级机器上实现的技术</u>
  - <u>解释：是在低一级机器级上用它的一串语句来等效高一级机器上的一条语句或指令的功能</u>
  - 一般来说，解释执行比翻译花的时间多，但占用的存储空间较少
  - 第1、2级是用解释方法实现的，而第3级及以上则用翻译方法实现
  - <u>软硬件在逻辑功能上是等效的。软件的功能可用硬件或固件完成，硬件的功能也可用软件模拟完成，只是性能、价格、实现的难易程度不同而已</u>
- <u>计算机系统设计者的主要任务：确定软硬件的分界；确定软件、硬件和固件的功能分配</u>

### 计算机系统结构、组成与实现

1. **计算机系统结构、组成、实现的定义：**
   - 计算机体系结构（Computer Architecture）俗称计算机系统结构
   - <u>定义一：计算机系统结构是程序员看到的计算机属性，即概念性结构与功能特性，实际上就是计算机系统的外特性</u>
   - <u>定义二：计算机系统结构的实质是计算机系统中软硬件界面的确定，界面之上的功能包括操作系统级、汇编语言级、高级语言级和应用语言级中所有软件的功能，界面之下的功能是硬件和固件的功能</u>
   - 就通用机而言，计算机系统结构的属性包括：
     - 硬件能直接识别和处理的数据类型和格式等的数据表示
     - 最小可寻址单位、寻址种类、地址计算等寻址方式
     - 通用/专用寄存器的设置、数量、字长、使用约定等寄存器组织
     - 二进制或汇编级指令的操作类型、格式、排序方式、控制机构等的指令系统
     - 内存的最小寻址单位、编址方式、容量、最大可编址空间等的存储系统组织
     - 中断的分类与分级、中断处理程序功能及入口地址等的中断机构
     - 系统机器级的管态和用户态的定义和切换
     - 输入输出设备的连接，使用方式、流量、操作结束、出错指示等机器级 I/O 结构
     - 系统各部分的信息保护方式和保护机构
   - <u>计算机组成（Computer Organization）指的是计算机系统结构的逻辑实现，包括机器级内的数据流和控制流的组成以及逻辑设计等</u>
   - <u>计算机实现（Computer Implementation）是指计算机组成的物理实现，包括处理机、内存的物理结构，器件的集成度和速度等</u>
   - <u>透明性：本来存在的事物或属性，从某种角度看似乎不存在</u>
   - e.g. 
     - 指令集的确定属于计算机系统结构，而指令集的实现属于计算机组成
     - 内存容量与编址方式（按位、按字节还是按字访问）的确定属于计算机系统结构；而为达到性能价格要求，内存速度应多快，采用何种逻辑结构则属于计算机组成
     - 中断的分级和中断的响应次序等中断机构都属于计算机系统结构的内容
     - 指令的操作码、字段格式、寻址方式是计算机系统结构的内容
     - 通用寄存器的使用属于计算机系统结构的内容
     - 单总线或是多总线是计算机组成的内容
     - 改变 CPU 和主存之间的数据通路宽度不影响体系结构
   - 如果两个计算机具有不同的计算机组成和相同的计算机系统结构，那么在其中一个计算机上编译后的目标程序。拿到另一个机器上也能运行，但两者的运行时间可能不同
2. **计算机系统结构、组成和实现的相互关系：**
   - <u>系统结构要考虑组成和实现的发展，不要有过多或不合理的限制</u>
   - <u>组成要考虑系统结构和实现，决定于系统结构，受限于实现</u>
   - <u>组成与实现不是被动的，需要同系统结构折中权衡</u>
   - <u>实现是物质基础</u>

### 软硬件取舍与计算机系统的设计思路

1. **软硬件取舍的基本原则：**
   - <u>在现有硬件和器件条件下，系统要有高的性能价格比</u>
   - <u>要考虑到准备采用和可能采用的组成技术，使它尽可能不要过多或不合理地限制各种组成、实现技术的采用</u>
   - <u>不能仅从“硬”的角度去考虑如何便于应用组成技术的成果和发挥器件技术的进展，还应从“软”的角度把为编译和操作系统的实现，以至高级语言程序的设计提供更多更好的硬件支持放在首位</u>
2. **计算机系统的设计思路：**
   - 由上往下设计（Top-Down）：适用专用机，不适用通用机
   - 由下往上设计（Bottom-Up）：很少被采用了
   - 从中间开始设计（Middle-Out）：中间指的是软硬件交界面，即在传统机器级与操作系统级之间

### 计算机设计的量化准则

1. **计算机系统设计的定量原则：**

   - Amdahl 定律：

     - <u>定律：当对系统中的某个部件进行改进后，所能获得的整个系统性能的提高，受限于该部件的执行时间占总执行时间的比例</u>

     - 加速比：
       $$
       加速比=\frac{改进后的性能}{改进前的性能}=\frac{改进前的总执行时间}{改进后的总执行时间}
       $$

     - 可改进比例 $Fe$：
       $$
       Fe=\frac{可改进部分占用的时间}{改进前整个任务的执行时间}
       $$

     - 性能提高比 $Se$：
       $$
       Se=\frac{改进前改进部分的执行时间}{改进后改进部分的执行时间}
       $$

     - 某部件改进后，整个任务的执行时间为 $T_n$：
       $$
       T_n=T_0\times(1-Fe+\frac{Fe}{Se})
       $$
       
     - 改进后整个系统的加速比 $S_n$：
       $$
       S_n=\frac{T_0}{T_n}=\frac{1}{(1-Fe)+\frac{Fe}{Se}}
       $$
     
   - CPU 性能公式：
   
     - 指令数（IC）
   
     - 程序执行的CPU时间为：
       $$
       CPU执行时间=\frac{CPU时钟周期数}{时钟频率}=\frac{IC \times CPI}{时钟频率}
       $$
   
     - 每条指令执行所需的时钟周期数（CPI）：是一个平均值
       $$
       CPI=\frac{CPU时钟周期数}{IC}
       $$
   
     - 假设有 $n$ 种指令，其中第 $i$ 种指令的处理时间为 $CPI_i$，在程序中第 $i$ 种指令出现的次数为 $I_i$，则：
       $$
       CPI=\frac{\sum_{i=1}^nCPI \times I_i}{IC}=\sum_{i=1}^{n}CPI_i \times \frac{I_i}{IC}
       $$
   
     - 每个时钟周期执行的指令数（IPC）：
       $$
       IPC=\frac{1}{CPI}
       $$
   
2. **衡量计算机系统的主要标准：**

   - 吞吐率和响应时间：

     - 吞吐率：计算机系统在单位时间内处理请求的数量
     - 响应时间：系统对请求作出响应的时间

   - 运算速度：

     - MIPS：每秒百万条指令（Million Instructions Per Second）
       $$
       MIPS=\frac{指令条数}{执行时间 \times 10^6}=\frac{主频}{CPI}=主频 \times IPC
       $$

     - MFLOPS：每秒百万次浮点运算（Million Floating-point Operations Per Second）
       $$
       MFLOPS=\frac{浮点操作次数}{执行时间 \times 10^6}
       $$

   - 等效指令速度：吉普森法
     $$
     等效指令执行时间 \space T=\sum_{i=1}^n(W_i \times T_i) \\
     等效指令速度 \space MIPS=\frac{1}{\sum_{i=1}^n \frac{W_i}{MIPS_i}} \\
     等效 \space CPI=\sum_{i=1}^n(CPI_i \times W_i) \\
     W_i：指令使用频度，i：指令种类
     $$
   
3. **计算机性能的比较**

4. **计算机系统的性能评价**

### 对系统结构的影响因素

1. **软件对系统结构的影响：**
   - <u>软件可移植性：软件不用修改或只需少量加工就能由一台机器搬到另一台机器上运行，即同一软件可以应用于不同的环境</u>
   - 实现软件可移植性的方法：
     - 采用统一的高级语言方法：采用一种不依赖于任何具体机器，可以满足各种应用需要的通用高级语言；短期内很难实现
     - 采用系列机方法：
       - <u>系列机是指同一厂家生产的具有相同结构，但具有不同组成组成和实现的一系列不同型号的计算机</u>
       - 优点：系列机之间软件兼容，可移植性好；插件、接口等相互兼容；便于实现机间通信；便于维修、培训；有利于提高产量，降低成本
       - 缺点：由于系统结构不准改变，限制了计算机系统结构的发展
       - 系列机的软件兼容：
         - 向上（下）兼容：按某档次机器编织的程序，不加修改就能运行在比它更高（低）档的机器上
         - 向前（后）兼容：按某档次机器编织的程序，不加修改就能运行在在它之前（后）投入市场的机器上
         - 对系列机的向下兼容和向前兼容不做要求，但是必须做到向后兼容，力争做到向上兼容
       - 兼容机：不同厂家生产的具有相同的系统结构的计算机系统
     - 采用模拟与仿真方法：
       - <u>模拟：模拟使用软件的方法在一台现有的计算机 A 上实现另一台计算机 B 的指令集；A 机器称为宿主机，B 机器称为虚拟机；通常用纯软件解释方法实现；运行速度较慢，性能较差</u>
       - <u>仿真：用一台现有计算机 A 上的微程序去解释实现另一台计算机 B 的指令系统；A 机器称为宿主机，B 机器称为目标机；需要硬件或固件的支持；比模拟方法快，但灵活性较小</u>
2. **器件和应用对系统结构的影响**

### 系统结构中的并行性

1. **并行性概念：**
   - <u>并行性是指计算机系统在同一时刻或同一时间间隔内进行多种运算或操作，只要在时间上重叠，就存在并行性。</u>
   - 并行性包含同时性和并发性两重含义：
     - <u>同时性：两个或多个事件在同一时刻发生</u>
     - <u>并发性：两个或多个事件在同一时间间隔内发生</u>
   - 开发并行性的途径：
     - <u>时间重叠：让多个处理过程在时间上相互错开，轮流重叠地使用同一套硬件设备的各个部分</u>
     - <u>资源重复：通过重复设置硬件资源来提高可靠性或性能</u>
     - <u>资源共享：利用软件的方法让多个用户按一定的时间顺序轮流地使用同一套资源，提高利用率，提高整个系统的性能</u>
2. **并行处理系统的结构与多机系统的耦合度：**
   - 并行处理计算机的结构：
     - 流水线计算机：使用时间重叠技术
     - 阵列处理机：使用资源重复技术
     - 多处理机系统：使用资源共享技术
     - 数据流计算机
   - 多机系统的耦合度：
     - 最低耦合系统：各种脱机处理系统
     - 松耦合系统：又称间接耦合系统；如果多台计算机通过通道或通信线路实现互连，共享某些如磁带、磁盘等外设，则称为松散耦合系统
     - 紧密耦合系统：又称直接耦合系统；如果多台计算机之间通过总线或高速开关互连，共享主存，则称为紧密耦合系统

### 计算机系统的分类

1. **Flynn 分类法：**
   - 指令流：计算机执行的指令序列
   - 数据流：由指令流调用的数据序列，包括输入数据和中间结果
   - 多倍性：在系统性能瓶颈部件上同时处于同一执行阶段的指令或数据的最大可能个数
   - 单指令流单数据流（Single Instruction stream Single Data stream，SISD）：传统单处理机
   - 单指令流多数据流（Single Instruction stream Multiple Data stream，SIMD）：阵列处理机和并行处理机
   - 多指令流单数据流（Multiple Instruction stream Single Data stream，MISD）：对于是否存在相应处理机存在争议
   - 多指令流多数据流（Multiple Instruction stream Multiple Data stream，MIMD）：包括大多数多处理机及多计算机系统
2. **其他分类法：**
   - 库克分类法
   - 冯泽云分类法
   - 汉德勒分类法

## 数据表示与指令系统

### 数据表示

1. **数据表示与数据结构：**
   - <u>数据类型：包括数据表示和数据结构</u>
   - <u>数据表示：是能由计算机硬件直接识别和引用的数据类型</u>
   - <u>数据结构：是通过软件映像，将信息变换成机器中所具有的各种数据表示来实现的；数据表示是构成数据结构的元素</u>
   - <u>数据结构和数据表示是软硬件的交界面；数据表示的确定实质上是软硬件取舍问题</u>
   - 机器的运算类指令和运算器结构主要是按机器由什么样的数据表示来确定的
2. **高级数据表示：**
   - 自定义数据表示：
     - 自定义数据表示包括带标志符的数据表示和数据描述符两类
     - 带标志符的数据表示：
       - 让每个数据都带有类型标志符，将数据类型与数据本身直接联系在一起
       - 这样，机器中的操作码也就和高级语言中的运算符一样，可以通用于各种数据类型的操作
       - 优点：
         - 简化了指令系统和程序设计
         - 简化了编译程序
         - 便于实现一致性校验
         - 能由硬件自动完成数据类型的变换
         - 支持了数据库系统的实现与数据类型无关的要求
         - 为软件调试和应用软件开发提供了支持
       - 缺点：
         - 每个数据字因增设标志符，可能会导致程序所占主存空间的增加，也可能不会
         - 采用标志符会降低指令的执行速度
         - 数据和指令的长度可能不一致
         - 硬件复杂度的增加
     - 数据描述符：
       - 为进一步减少标志符所占的存储空间，对于向量、数组等多维或结构复杂的数据，由于每个元素具有相同的属性，没有必要让每个数据结构都带有标志符
       - 数据描述符和标志符的区别在于，标志符描述单个数据的类型和属性（作用于一个数据），二描述符主要用于描述成块数据的特征（作用于一组数据）
       - 数据描述符表示法的优缺点与带标志符数据表示法相同，但机器结构会比带标志符数据表示法更复杂
   - 向量数据表示：为向量、数组数据结构的实现和快速运算提供更好的硬件支持的方法是增设向量、数组数据表示，组成向量机
   - 堆栈数据表示：堆栈数据结构在编译和子程序调用中很有用，为高效实现，不少机器设有堆栈数据表示；有堆栈数据表示的计算机称为堆栈机
3. **引入数据表示的原则：**
   - <u>引入数据表示后，系统的效率是否提高，即是否减少了实现时间和所需的存储空间。衡量实现时间是否减少，主要看在主存和处理机之间传送的信息量是否减少</u>
   - <u>引入数据表示后，其通用性和利用率是否提高</u>

### 寻址方式

寻址方式：寻找操作数及数据存放单元的方法

1. **寻址方式分析：**
   - 立即数寻址：
     - 优点：不需要数据存储单元，指令执行速度快
     - 缺点：只能用于源操作数寻址，数据长度不能太长
   - 寄存器寻址：
     - 优点：指令字长短，执行速度快，支持向量，矩阵运算
     - 缺点：不利于优化编译，现场切换困难，硬件复杂
   - 主存寻址：直接寻址、间接寻址、变址寻址（相对寻址和基址寻址）
   - 堆栈寻址
2. **间接寻址方式与变址寻址方式的比较：**
   - 间接寻址方式是将间接地址保存在主存储器中，没有偏移量
   - 变址寻址方式是将基地址保存在变址寄存器中，有偏移量
   - 比较：
     - 实现的难易程度：间接寻址方式实现容易；变址寻址方式需要增加较多硬件
     - 指令的执行速度：采用间接寻址方式编写的程序执行速度慢；变址寻址方式编写的程序执行速度快
     - 对数组运算的支持：变址寻址方式较好，带有偏移量；间接寻址较差
3. **程序在主存中的定位技术：**
   - <u>逻辑地址指的是程序员编写程序时使用的地址，主存物理地址指的是程序在主存中的实际地址</u>
   - 程序和数据存放在主存中的位置是由程序员编程时指明的，这种方式称为直接定位方式
   - 根据程序的主存物理地址确定的时间，程序定位方式分为：
     - <u>静态再定位：在程序装入主存储器的过程中随即进行地址变换，确定指令和数据的主存物理地址</u>
     - <u>动态再定位：在程序执行过程中，当访问到相应的指令或数据时才进行地址变换，确定指令和数据的主存物理地址</u>
   - 信息在主存中按整数边界存储对于保证访问速度是必要的

### 指令系统的设计和优化

1. **指令操作码的优化：**
   - 要在足够表达全部指令的前提下，使操作码字段占用的位数最少
   - 操作码优化主要是为了缩短指令字长，减少程序总位数，节省程序的存储空间
   - 哈夫曼（Huffman）压缩：对发生概率最高的事件用最短的位数（时间）来表示（处理），对发生频率较低的事件允许用较长的位数（时间）来表示（处理），就会使表示（处理）的平均位数（时间）缩短
   - 按照信息论的观点，操作码的信息源熵 $H=-\sum_{i=1}^np_i \log_2 p_i$；信息源熵的直观意义是要表达给定数目个指令，需要 $H$ 位的指令位
   - 信息冗余：$信息冗余=\frac{实际平均码长-H}{实际平均码长}$
   - 哈夫曼编码：:book:
     - 也称为最小概率合并法
     - 核心是指令使用频率不同，采用不等长编码
     - 编码原理 :book:
     - 编码方式 :book:
     - 哈夫曼编码是最优化的编码
     - 哈夫曼编码的具体码值不唯一，但平均码长肯定是唯一的
     - 缺点：
       - 操作码长度很不规整，硬件译码困难
       - 与地址码共同组成固定长的指令比较困难
     - 哈夫曼编码遵循短码不能是长码的前缀
   - 扩展操作码：
     - 是由固定长操作码与哈夫曼编码法相结合形成的一种编码方式，操作码长度被限定使用有限的几种码长，仍体现高概率指令用短码，低概率指令用长码的哈夫曼压缩思想；是一种实际可用的优化编码方式
     - 等长扩展与不等长扩展
     - 扩展操作码必须遵循短码不能是长码的前缀
     - 扩展操作码的编码不唯一，平均码长也不唯一，关键在于找出一种平均码长尽可能短，又能使码长种类数不过多的、便于优化实现的方案
2. **指令字格式的优化：**
   - 通过各种方式缩短指令中的地址码的位数
   - 使用多种指令字长，比只有一种长度的定长指令字更能减少信息的冗余量，缩短程序的长度

### 指令系统的发展和改进

1. **CISC 和 RISC：**
   - <u>复杂指令系统计算机（Complex Instruction Set Computer，CISC）：进一步增强原有指令的功能以及设置更为复杂的新指令取代原先由软件子程序完成的功能，实现软件功能的硬化</u>
   - <u>精简指令系统计算机（Reduced Instruction Set Computer，RISC）：减少指令种类和简化指令功能来降低硬件设计的复杂度，提高指令的执行速度</u>
2. **按 CISC 方向发展与改进指令系统：**
   - 存在问题：
     - 各种指令的使用频度相差悬殊：“二八定律”
     - 控制硬件复杂
     - CPI 值较大，执行速度慢
     - 不利于采用流水线技术
3. **按 RISC 方向发展与改进指令系统：**
   - 设计 RISC 的基本原则：
     - 确定指令系统时，只选择使用频率很高的那些指令，在此基础上增加少量能有效支持操作系统和高级语言实现及其他功能的最有用的指令，让指令条数大大减少，一般不超过100条
     - 大大减少指令系统可采用的寻址方式的种类，一般不超过两种，指令的格式也限制在两种之内，并让全部指令都具有相同的长度
     - 让所有指令都在一个机器周期内完成
     - 扩大通用寄存器的个数，一般不少于32个寄存器，以尽可能减少访存操作，所有指令中只有存（Store）、取（Load）指令才可访存，其他指令的操作一律只对寄存器操作
     - 为提高指令执行速度，大多数指令都采用硬联控制实现，少数指令采用微程序实现
     - 通过精简指令和优化设计编译程序，以简单有效的方式来支持高级语言的实现
   - 减少 CPI 是 RISC 思想的精华
4. **设计 RISC 的关键技术：**
   - 重叠寄存器窗口技术：
     - 设置一个数量比较大的寄存器堆，并把它划分成很多个窗口。在每个过程使用的几个窗口中有一个窗口是与前一个过程共用的，还有一个窗口是与下一个过程共用的
   - 延迟转移技术：
     - 为了使指令流水线不断流，在转移指令之后插入一条不相关的有效的指令，而转移指令被延迟执行
     - 采用指令延迟转移技术时，指令序列的调整由编译器自动进行
   - 指令取消技术：:question:
     - 采用指令延时技术，在许多情况下找不到可以用来调整的指令
     - 向后转移
     - 向前转移
     - 隐含转移技术
   - 指令流调整技术：通过变量重新命名消除数据相关，提高流水线执行效率
   - 采用认真设计和优化编译系统设计的技术

## 输入/输出系统

### 输入输出系统概述

- 在计算机系统中，通常把处理机与主存储器之外的部分称为输入/输出系统，它包括输入/输出设备、输入/输出接口和输入/输出软件等
- 输入/输出系统的特点集中反映在异步性、实时性和与设备无关性这三项基本要求上，它们对输入/输出的组织产生决定性的影响：
  - 异步性：输入输出设备的工作在很大程度上独立于处理机之外，通常不适用统一控制的中央时钟，各个设备按照自己的时钟工作，但又要在某些时刻接受处理机的控制
  - 实时性
  - 与设备无关性：处理机无需了解各种外设特定的具体工作细节，可以采用统一的硬件和软件对品种繁多的设备进行管理
- 输入输出系统包括三种方式：
  - 程序查询
  - 程序中断
  - 直接存储器访问（DMA）

### 磁盘阵列

- 独立冗余磁盘阵列（Redundent Array of Independent Disk，RAID）：一种使用磁盘驱动器的方法，将一组磁盘驱动器用某种逻辑方式联系起来，作为逻辑上的一个磁盘驱动器来使用，一般情况下，组成的逻辑磁盘驱动器的容量要小于各个磁盘驱动器容量的总和

- 优点：

  - 成本低、功耗小，传输速率高
  - 提供容错能力
  - RAID 比起传统的大直径磁盘驱动器来说，在同样的容量下，价格较低

- 各级 RAID 的对比：

  | RAID 级别 |                名称                | 数据磁盘数 | 可正常工作的最多失效磁盘数 | 检测磁盘数 |
  | :-------: | :--------------------------------: | :--------: | :------------------------: | :--------: |
  |   RAID0   |       无冗余无校验的磁盘阵列       |     8      |             0              |     0      |
  |   RAID1   |            镜像磁盘阵列            |     8      |             1              |     8      |
  |   RAID2   |         纠错海明码磁盘阵列         |     8      |             1              |     4      |
  |   RAID3   |      位交叉奇偶校验的磁盘阵列      |     8      |             1              |     1      |
  |   RAID4   |      块交叉奇偶校验的磁盘阵列      |     8      |             1              |     1      |
  |   RAID5   |   无独立校验盘的奇偶校验磁盘阵列   |     8      |             1              |     1      |
  |   RAID6   | 双维无独立校验盘的奇偶校验磁盘阵列 |     8      |             2              |     2      |

### 总线设计

1. **总线特点：**

   - <u>总线是一组能为多个部件分时共享的公共信息传送线路</u>
- <u>分时：同一时刻总线上只能传送一个部件发送的消息</u>
   - <u>共享：总线上可以挂接多个部件，多个部件之间相互交换的信息都可以通过这组公共线路传送</u>
   - 优点：成本低、简单
   - 缺点：总线的带宽形成了信息交换的瓶颈，限制了系统中总的 I/O 吞吐率
   - 总线事务
   - 总线使用权：
     - 主存总是从设备，它不会主动提出要与谁交换信息的要求

2. **总线的数据宽度：**

   - 数据宽度是 I/O 设备取得 I/O 总线后所传送数据的总量，不同于数据通路的宽度。数据通路宽度是数据总线的物理宽度，也就是数据总线的线数。数据宽度有单字、定长块、变长块、单字加定长块和单字加变长块等
   - 单字宽度：适用于低速设备
   - 定长块宽度：适用于高速设备
   - 变长块宽度：适用于高优先级的中高速设备
   - 单字加定长块宽度：适用于高优先级的低速设备
   - 单字加变长块宽度：是一种灵活有效但复杂、花钱的方法

3. **总线定时控制：**

   - 同步定时方式：
     - 是指系统系统采用一个统一的时钟信号来协调发送和接收双方的传送定时关系。时钟产生相等的时间间隔，每个时间间隔构成一个时钟周期。在一个总线周期中，发送和接收双方进行一次数据传送
     - 同步方式的效率较低；时间利用不够合理；可靠性较低
   - 异步定时方式：
     - 也称为应答方式，没有公用的时钟，也没有固定的时间间隔，完全依靠传送双方相互制约的“握手”信号实现定时控制
     - 根据“请求”和“回答”信号的撤销是否互锁，可以分为：
       - 不互锁
       - 半互锁
       - 全互锁

4. **总线的集中仲裁方式：**

   - 为了保证同一时刻只有一个申请者使用总线，总线控制机构中设置有总线判优和仲裁控制逻辑，即按照一定的优先次序来决定哪个部件首先使用总线，只有获得总线使用权的部件，才能开始数据传送
   - <u>链式查询方式</u>
   - <u>计数器定时查询方式</u>
   - <u>独立请求方式</u>

5. **总线的分布仲裁方式：**

   - 分布式仲裁方式不需要中央仲裁器，即总线控制逻辑分散在连接于总线上的各个部件或设备中。连接到总线上的主方可以启动一个总线周期，而从方只能相应主方的请求。每次总线操作，只能有一个主方占用总线使用权，但同一时间里可以有一个或多个从方
   - 自举分布式
   - 冲突检测分布式
   - 并行竞争分布式

### 通道处理机

1. **通道的作用和功能：**

   - 传统的输入/输出方式的问题：
     - CPU 负担重：
       - 程序查询：所有外设的输入/输出工作均由 CPU 承担，不能充分发挥 CPU 的计算能力
       - 程序中断：每传送一个字符都由 CPU 执行一段程序来完成；适用于低速设备
       - DMA：初始化、前处理和后处理等工作需要 CPU 来完成；适用于高速外围设备
     - 接口数量多
   - 通道的功能：
     - 接收 CPU 发来的 I/O 指令，并根据指令要求选择一台指定的外围设备与通道相连
     - 执行通道程序
     - 给出外部设备的有关地址
     - 给出主缓冲区的首地址
     - 控制外设与主存缓冲区之间的数据交换的个数
     - 指定传送工作结束后要进行的操作
     - 检查外设的工作状态是否正常，并将该状态信息送往主存指定单元保存
     - 在数据传输过程中完成必要的格式变换
   - 通道的硬件组成

2. **通道的工作过程：**

   - 主要过程分三步：
     - 在用户程序中使用访管指令进入管理程序，由 CPU 通过管理程序组织一个通道程序，并启动通道
     - 通道执行 CPU 为它组织的通道程序，完成指定的数据输入/输出工作
     - 通道程序结束后向 CPU 发中断请求。CPU 响应这个中断请求后，第二次调用管理程序对中断请求进行处理
   - 每完成一次输入/输出工作，CPU 只需要两次调用管理程序，大大减少了对用户程序的打扰

3. **通道的类型：**

   - 字节多路通道：

     - 字节多路通道是一种简单的共享通道，用于连接与管理多台低速设备，以字节交叉方式传送信息
     - 一个字节多路通道，包括多个按字节方式传送信息的子通道。每个子通道服务于一个设备控制器，每个子通道都可以独立地执行通道程序
     - 这种轮流服务是建立在主机的速度比外设的速度高得多的基础之上，它可以提高系统的工作效率

   - 选择通道：

     - 选择通道又称高速通道，在物理上它也可以连接多个设备，但这些设备不能同时工作，在一段时间内通道只能选择一台设备进行数据传送，此时该设备可以独占整个通道
     - 选择通道主要用于连接高速外设，如磁盘、磁带等，信息以成组方式高速传送
     - 在数据传送中还有一些辅助操作（如磁盘的寻道），此时会使通道处于等待状态，所以虽然选择通道具有很高的数据传输速率，但整个通道的利用率不高

   - 数组多路通道：

     - 当某个进行数据传送时，通道只为该设备服务；当设备在执行辅助操作时，通道暂时断开与这个设备的连接，挂起该设备的通道程序，去为其他设备服务
     - 选择通道和数组多路通道都适用于连接高速外设，但前者的数据宽度是不定长的数据块，后者的数据宽度是定长的数据块

   - 三者比较：

     |              | 字节多路通道 |      选择通道      | 数组多路通道 |
     | :----------: | :----------: | :----------------: | :----------: |
     |   数据宽度   |    单字节    |      不定长块      |    定长块    |
     |   适用范围   | 大量低速设备 | 优先级高的高速设备 | 大量高速设备 |
     |   工作方式   |   字节交叉   |      独占通道      |   成组交叉   |
     |    共享性    |   分时共享   |        独占        |   分时共享   |
     | 选择设备次数 |     多次     |        一次        |     多次     |

4. **通道中的数据传输过程：**

   - $T_S$：设备选择时间。从通道需要设备发出数据传送请求开始，到通道实际为这台设备传送数据所需要的时间

   - $T_D$：传送一个字节所用的时间，实际上就是通道执行一条通道指令，即数据传送指令所用的时间

   - $P$：在一个通道上连接的设备台数，且这些设备同时都在工作

   - $n$：每个设备传送的字节个数，这里，假设每一台设备传送的字节数都相同，都是 $n$ 个字节

   - $D_{ij}$：连接在通道上的第 $i(i=1,2,\dots,p)$ 台设备传送的第 $j(j=1,2,\dots,n)$ 个数据

   - $T$：通道完成全部数据传送工作所需要的时间

   - 当一个字节多路通道上连接有 $P$ 台设备，每台设备都传送 $n$ 个字节时，所需要的时间为：
     $$
     T_{Byte}=(T_S+T_D) \times P \times n
     $$

   - 当一个选择通道连接 $P$ 台设备，每台设备都传送 $n$ 字节时，所需要的时间为：
     $$
     T_{Select}=(\frac{T_S}{n}+T_D) \times P \times n
     $$

   - $k$：一个数据块中的字节个数；一般情况下，$k<n$

   - 当一台数组多路通道连接 $P$ 台设备，每台设备都传送 $n$ 个字节，所需要的时间为：
     $$
     T_{Block}=(\frac{T_S}{k}+T_D) \times P \times n
     $$
   
5. **通道的流量分析：**

   - 通道流量是指通道在数据传送期内，单位时间里传送的字节数。它能达到的最大流量称为通道极限流量

   - 字节多路通道：
     $$
     f_{max \cdot Byte}=\frac{P \times n}{(T_S+T_D) \times P \times n}=\frac{1}{T_S+T_D}
     $$

   - 选择通道：
     $$
     f_{max \cdot Select}=\frac{P \times n}{(\frac{T_S}{n}+T_D) \times P \times n}=\frac{n}{T_S+nT_D}
     $$

   - 数组多路通道：
     $$
     f_{max \cdot Block}=\frac{P \times n}{(\frac{T_S}{k}+T_D) \times P \times n}=\frac{k}{T_S+kT_D}
     $$

   - 若接上 $P$ 台设备，则通道要求的实际流量分别为：

     - 字节多路通道：即所接 $P$ 台设备的速率之和
       $$
       f_{Byte}=\sum_{i=1}^Pf_i
       $$

     - 选择通道：即所接 $P$ 台设备中速率最高者
       $$
       f_{Select}=\max_{i=1}^{P}f_i
       $$

     - 数组多路通道：即所接 $P$ 台设备中速率最高者
       $$
       f_{Block}=\max_{i=1}^{P}f_i
       $$

   - 为使通所接外部设备在满负荷工作时仍不丢失信息，应使通道的实际最大流量不能超过通道的极限流量

   - 如果在 I/O 系统中有多个通道，各个通道是并行工作的，则 I/O 系统的极限流量应当是各通道或各子通道工作时的极限流量之和

   - 当字节多路通道的最大流量与连接在这个通道上的所有设备的数据流量之和非常接近时，虽然能够宏观上通道不丢失设备的信息，但不能保证在某个局部时刻不丢失信息。可以采用以下措施：

     - <u>增加通道的最大流量</u>
     - <u>动态改变设备的优先级</u>
     - <u>增加一定数量的数据缓冲器，特别是对优先级比较低的设备</u>

## 存储体系

### 存储体系概念和并行存储系统

1. **存储体系的引出：**

   - <u>存储器的性能通常用速度、容量和价格三个主要指标来表示；三者是矛盾的，速度越快、容量越大、价格就越贵</u>
   - 容量：用字节（B）、千字节（KB）、兆字节（MB）和千兆字节（GB）等单位表示
   - 价格：用单位容量的价格表示，如 $/b
   - 速度：可以用访问之间、存储周期和频宽（也称带宽）来描述
   - <u>存储系统的关键是如何组织好速度、容量和价格均不相同的存储器，使这个存储器系统的速度接近速度最快的那个存储器，存储容量与容量最大的那个存储器相等，单位容量的价格接近最便宜的那个存储器</u>

2. **并行存储系统：**

   - <u>能并行独处多个 CPU 字的单体多字、多体单字或多体多字的交叉访问存储系统称为并行存储系统</u>
   - 方法：把 $m$ 字 $W$ 位的存储器改变为 $m/n$ 字 $n \times W$ 位的存储器，在一个存储周期内就可以读出 $n$ 个字
   - 缺点：
     - 取指令冲突，由于程序有转移
     - 读操作数冲突，同时读出存储字的数据不一定都有用
     - 写数据冲突，要凑齐几个数据成一个存储字才能写
     - 读写冲突，由于读、写的数据可能处于同一个存储字
   - 程序的局部性原理：
     - <u>时间局部性：最近访问的代码是不久将要访问的代码，这是由于程序的循环造成的</u>
     - <u>空间局部性：地址上相临近的代码可能会被一起访问，这主要是由于指令通常是顺序执行的，以及数据一般是以向量、数组、树、表、阵列等形式簇聚地存储所致的</u>
   - 高位交叉访问存储器：高位交叉访问存储器的主要目的是扩大存储器容量。其具体的实现方法是用地址码的高位区分存储体号，低位地址为体内地址
   - 低位交叉访问存储器：低位交叉访问存储器的主要目的是提高存储器访问速度，还可以解决访问冲突问题。其实现方法是用地址码的低位区分存储体号，高位是体内地址

3. **存储体系定义和分支：**

   - <u>存储体系的定义：两个或两个以上速度、容量和价格各不相同的存储器用硬件、软件或软件与硬件相结合的方法连接起成为一个存储系统（存储体系、存储层次）这个系统对应用程序员透明，并且，从应用程序员看，它是一个存储器，这个存储器的速度接近速度最快的那个存储器，存储容量与容量最大的那个存储器相等，单位容量的价格接近最便宜的那个存储器</u>
   - 存储体系分支：基本的两级存储体系是虚拟存储系统和 Cache 存储系统，这是存储体系的两个不同分支
     - 主存-辅存存储层次（虚拟存储系统）：由主存储器和联机的辅存（磁盘存储器）构成，其主要目的是扩大存储器容量，弥补主存容量的不足
     - Cache-主存存储层次（Cache 存储系统）：由 Cache 和主存储器构成，其主要目的是提高存储器速度，弥补主存速度的不足

4. **存储体系的性能参数：**

   - 现有两级存储体系 $(M_1,M_2)$

   - 存储系统的每位平均价格为：
     $$
     c=\frac{c_1S_{M_1}+c2S_{M_2}}{S_{M_1}+S_{M_2}}
     $$
     其中 $c_1$ 是 $M_1$ 的每位价格，$S_{M_1}$ 为 $M_1$ 的按位计算的存储容量，其余同理

   - 命中率：
     $$
     H=\frac{R_1}{R_1+R_2}
     $$

   - 等效访问时间：

     - 假设 $M_1$ 访问和 $M_2$ 访问时同时启动的：
       $$
       T_A=H \times T_{A_1}+(1-H) \times T_{A_2}
       $$

     - 假设 $M_1$ 不命中才启动 $M_2$：
       $$
       T_A=T_{A_1}+(1-H) \times T_{A_2}
       $$

   - 存储器的访问效率：
     $$
     e=\frac{T_{A_1}}{T_A}=\frac{T_{A_1}}{HT_{A_1}+(1-H)T_{A_2}}=\frac{1}{H+(1-H)r},r=\frac{T_{A_2}}{T_{A_1}}
     $$

   - 存储系统的访问效率主要与命中率和两级存储器的速度之比有关。效率值越大，访问速度与速度快的存储器越接近。若想让 $T_A$ 越接近于 $T_{A_1}$，即接近与比较快的 $M_1$，也就是让存储层次的访问效率接近于1。总之，希望命中率比较高

   - 采用预取技术提高命中率：

     - 不管需要还是不需要，把需要字的前前后后都一起取过来，即取一个数据块

     - 具体方法是不命中时，把 $M_2$ 存储器中相邻几个单元组成的一个数据块都取出来送入 $M_1$ 存储器中，命中率为：
       $$
       H'=\frac{H+n-1}{n}
       $$
       $n$ 为数据块大小与数据重复使用次数的乘积

   - 提高存储系统效率的途径：

     - <u>提高命中率</u>
     - <u>两级存储器的速度相差不要太大</u>
     - <u>加快内部地址映像及变换</u>

### 虚拟存储系统

1. **虚拟存储管理方式：**

   - 段式存储管理方式

   - 页式存储管理方式：

     - 将主存空间和程序空间机械地等分成固定大小的页面
     - 主存（实存）的页称为实页，虚存的页称为虚页
     - 由地址映像机构将虚页号转换成主存的实页号
     - 地址变换过程

   - 段页式存储管理方式

   - 三种方法的比较

   - 造成虚拟存储器速度降低的主要原因：

     - 要访问主存储器须先查段表或者页表
     - 可能需要多级页表

   - 页表级数的计算公式：
     $$
     g=\lceil \frac{\log_2Nv-log_2Np}{log_2Np-log_2Nd} \rceil
     $$
     其中，$Np$ 为页面大小，$Nv$ 为虚拟存储空间大小，$Nd$ 为一个页表存储字的大小

2. **页式虚拟存储系统构成：**

   - 一个主存地址由两部组成：实页号和页内偏移
   - 一个多用户虚拟地址由三部分组成：用户号、虚页号和页内偏移

   - 地址映像和变换：
     - <u>地址映像：每一个虚存单元将按什么规则（算法）装入实存，即建立多用户虚拟地址与实主存地址之间的对应关系</u>
     - <u>地址变换：程序按照这种映像关系装入实存后，在执行时，多用户虚地址如何变换成对应的实地址</u>
   - 内部地址变换和外部地址变换：
     - <u>内部地址变换：虚页号变换成主存实页号，进而多用户虚拟地址变换成主存实地址。所需要的页在主存称作内部地址变换，查内页表</u>
     - <u>外部地址变换：如果内部地址变换失败（不命中），所需要的页不在内存，必须访问磁盘（辅存），就要进行外部地址变换。虚页号变换成磁盘实地址，主要由软件实现</u>
   - 页面替换算法：
     - 页面失效和页面冲突：
       - <u>页面失效：是该页未装入主存，需要从辅存中调页</u>
       - <u>页面冲突（页面争用）：两个以上的虚页想要进入主存中同一个页面位置的现象</u>
       - <u>页面失效不一定发生页面冲突，但页面冲突一定是页面失效引起的</u>
     - 替换算法的确定主要是看按这种替换算法替换是否有高的主存命中率，其次要看替换算法是否便于实现，辅助软硬件成本是否低
     - 页面替换算法的使用场合：
       - 虚拟存储器中，主存页面的替换，一般用软件实现
       - Cache 块替换一般用硬件实现
       - 虚拟存储器的快慢表中，快表存储字的替换，用硬件实现
       - 虚拟存储器中，用户基地址寄存器的替换，用硬件实现
       - 在有些虚拟存储器中目录表的替换
     - 随机算法（Random algorithm，RAND）：算法简单，容易实现；没有利用历史信息，没有反映程序的局部性，命中率低
     - 先进先出算法（First-In First-Out algorithm，FIFO）：比较容易实现，利用了历史信息，没有反映程序的局部性。最先调入主存的页面，很可能也是经常要使用的页面
     - 近期最少使用算法（Least Frequently Used algorithm，LFU）：既充分利用了历史信息，又反映了程序的局部性，实现起来非常困难
     - 最久没有使用算法（Least Recently Used algorithm，LRU）：把LFU算法中的“多”与“少”简化成“有”与“无”，实现起来比较容易；有堆栈法和比较对法两种实现
     - 最优替换算法（OPTimal replacemant algorithm，OPT）：是一种理想化的算法。用来作为评价其它页面替换算法好坏的标准
     - 在虚拟存储器中，实际上有可能采用只有 FIFO 和 LRU 两种算法
     - 堆栈型替换算法：OPT、LRU
     - 具体流程和例子：:book:
   - 页式虚拟存储系统工作的全过程

3. **页式虚拟存储系统实现中的问题：**

   - <u>页面失效的处理：页面失效会在一条指令的分析和执行过程发出。页面失效不能按一般的中断对待，应看作一种故障，一旦出现，处理机必须立即予以响应和处理</u>
   - 提高虚拟存储系统等效访问速度的措施：
     - 目录表：用一个小容量高速存储器存放页表；目录表是相联访问的，容量越大，命中率越高；容量越大，相联查找的速度也越慢，命中率与查表速度是矛盾的
     - 快慢表：
       - 快表（Translation Lookaside Buffer，TLB）：小容量（几~几十个字），高速硬件实现，采用相联方式访问
       - 慢表：当快表中查不到时，从存放在主存储器中的慢表中查找按地址访问，用软件实现。快表与慢表也构成了一个两级存储系统
     - 散列函数：
       - 目的：把相联访问变成按地址访问，从而加大快表容量
       - 采用散列变换实现快表按地址访问；让虚页号与存放该虚页号的块表地址之间有某种散列函数关系
       - 避免散列冲突：采用相等比较器
       - 地址变换过程：相等比较与访问存储器同时进行

### 高速缓冲存储器

1. **地址映像和变换：**
   - <u>地址映像：主存中程序怎么放到 Cache 中是地址映像。地址映像是把存放在主存中的程序按照某种规则装入 Cache 中，并建立主存地址与 Cache 地址之间的对应关系</u>
   - <u>地址变换：主存地址与 Cache 地址之间如何进行变换就是地址变换。地址变换是当程序已经装入 Cache 之后，在实际运行过程中，把主存地址变换成 Cache 地址</u>
   - 选取地址映像方法要考虑的主要因素有：
     - 地址变换的硬件要容易实现
     - 地址变换的速度要快
     - 主存空间利用率要高
     - 发生块冲突的概率要小
   - 地址映像的方法：:book:
     - 全相联映像（Fully Associative Mapping）和变换：
       - 就是让主存中任何一个块均可以映像装入 Cache 中任何一个块的位置上。块随便放，只要 Cache 有空
       - 全相联映像方式的 Cache 的块冲突概率是最低的，物理 Cache 的空间利用率是最高的；但由于用于地址映像的相联目录表容量太大，成本极高，查表进行地址变换的速度太低
     - 直接映像（Direct Mapping）和变换：
       - 主存中的每一个块只能被放置到 Cache 中唯一的一个指定位置，若这个位置已有放了一块，则产生块冲突，原来的块将被无条件地替换出去
       - 直接映像方式成本低，易实现，地址变换速度快，而且不涉及其他两种方式中的替换算法问题；但 Cache 的块冲突概率是最高的，物理 Cache 的空间利用率是最低的
     - 组相联映像（Set Associative Mapping）和变换：
       - 将主存和 Cache 按同样大小划分成块，Cache 空间等分成大小相同的组，组里有若干个块。让主存中的任何一块只能被放置到 Cache 中唯一的一个指定组，均可全相联映像装入 Cache 中对应组的任何一块位置上，即组间采取直接映像，而组内采取全相联映像
       - 组相联映像方式块的冲突概率比较低，块的利用率大幅度提高，块失效率明显减低；实现难度和造价要比直接映像方式高
2. **替换算法的实现：**
   - 替换算法的使用时机：发生块失效，且可以装入新调入块的几个Cache块都已经被装满时
   - 直接映像方式实际上不需要替换算法
   - 全相联映像方式的替换算法最复杂
3. **Cache 的透明性及性能分析：**
   - Cache 的透明性分析：
     - Cache 存储层次对系统程序员和应用程序员都是透明的
     - 造成 Cache 与主存不一致的原因有：
       - 由于 CPU 写 Cache，没有立即写主存，主存单元内容没变。若把在主存的数据输出到设备，就是过时的数据
       - 由于 I/O 处理机或 I/O 设备写主存，Cache 单元内容没变，CPU 要读 Cache 中的内容就是错误的
     - Cache 存储系统的更新算法：
       - <u>写直达法（Write-Through，WT）：又称写透法。CPU 在执行写操作时，把数据同时写入 Cache 和主存。写直达法速度慢，相当于主存的速度，但能保证 Cache 与主存一致</u>
       - <u>写回法（Write-Back，WB）：CPU 数据只写入 Cache，不写入主存，仅当替换时，才把修改过的 Cache 块写回到主存</u>
     - 写 Cache 的两种方法：
       - 不按写分配法：在写 Cache 不命中时，只把所要写的字写入主存，即该地址所对应的数据块不从主存调入 Cache
       - 按写分配法：在写 Cache 不命中时，还把一个块从主存读入 Cache，包括所写字的数据块从主存读入
       - 目前，在写回法中采用按写分配法，在写直达法中采用不按写分配法
     - 对于单处理机系统的 Cache，多数采用写回法，目的是减少 Cache 与主存之间的通信量。单处理机系统的 Cache 存储系统多采用写回法以节省成本；共享主存的多处理机系统，为保证各处理机经主存交换信息时不出错，较多采用写直达法。写直达法是为了硬件的控制比较简单
   - Cache 的预取算法：
     - 按需取：在出现Cache不命中时，把一个块取到Cache中来
     - 恒预取：无论Cache是否命中，都把下一块取到Cache中
     - 不命中预取：当Cache不命中，把本块和下一块取到Cache中
     - 可以提高 Cache 的命中率；但 Cache 与主存之间通信量的增加
   - 任务切换对失效率的影响
   - 影响 Cache 存储系统性能的因素
   - Cache 存储系统的性能分析

## 流水线和向量机

### 重叠方式

1. **重叠原理和一次重叠：**

   - 顺序执行方式：执行 $n$ 条指令所用的时间为：
     $$
     T=\sum_{i=1}^{n}(t_{取指令_i}+t_{分析_i}+t_{执行_i})
     $$
     若取指令、分析和执行的时间都为 $t$，则：
     $$
     T=3nt
     $$

   - 顺序执行方式的优缺点：

     - 优点：控制简单，节省设备
     - 缺点：执行指令的速度慢，功能部件的利用率很低

   - 一次重叠：将执行第 $k$ 条指令同取第 $k+1$ 条指令同时执行，一种最简单的流水线方式。若取指令、分析和执行的时间都为 $t$，则：
     $$
     T=(2n+1)t
     $$

   - 一次重叠的优缺点：

     - 优点：指令的执行时间缩短；功能部件的利用率明显提高
     - 缺点：需要增加一些硬件；控制过程稍复杂

   - 二次重叠方式：将执行第 $k$ 条指令、分析第 $k+1$ 条指令和取第 $k+2$ 条指令同时执行。若取指令、分析和执行的时间都为 $t$，则：
     $$
     T=(n+2)t
     $$
     处理机的结构要作比较大的改变，必须采用先行控制方式

   - 采用二次重叠方式，必须要解决两个问题：

     - 有独立的取指令部件、指令分析部件和指令执行部件
     - 要解决访问主存储器的冲突问题。取指令、分析指令、执行指令都可能要访问存储器

   - 解决访存冲突的方法：

     - 采用低位交叉存取方式：这种方法不能根本解决冲突问题
     - <u>两个独立的存储器：独立的指令存储器和数据存储器。在许多高性能处理机中，有独立的指令 Cache 和数据 Cache。这种结构被称为哈佛结构</u>
     - 采用先行控制技术：先行控制技术的关键是缓冲技术和预处理技术
       - <u>缓冲技术：在工作速度不固定的两个功能部件之间设置缓冲栈，用以平滑它们的工作</u>
       - <u>预处理技术：早些取来指令和操作数</u>

2. **相关处理：**

   - <u>推后读</u>
   - <u>设置相关专用通路</u>

### 流水方式

1. **基本概念：**

   - 流水是重叠的引申：流水和重叠的差别只在于“一次重叠”是把一条指令的解释分为两个子过程，而流水是分为更多个子过程
   - 采用流水线方式后，机器的最大吞吐率取决于子过程的经过时间 $\Delta t$
   - 流水线的每一个子过程即阶段（Stage），又称为流水步、流水步骤、流水段、流水线阶段、流水功能段、功能段、流水级或流水节拍等
   - 流水线的表示方法：
     - 连接图
     - 时空图
     - 预约表
   - 流水线的主要特点：
     - 只有连续提供同类任务才能充分发挥流水线的效率：对于指令流水线，要尽量减少因条件分支造成的“断流”，转移和不转移的分支都预取；对于操作部件，主要通过编译技术，尽量提供连续的同类操作
     - 在流水线的每一个流水线段中都要设置一个流水锁存器：流水线的执行时间加长；是流水线中需要增加的主要硬件之一
     - 各流水段的时间应尽量相等：流水线处理机的基本时钟周期等于时间最长的流水段的时间长度
     - 流水线需要有“装入时间”和“排空时间”
   - 流水线的分类：
     - 按照流水线的处理级别的高低来分：
       - 部件级流水线（操作流水线）：指构成部件的各子部件间的流水。如浮点加法器流水线
       - 处理机级流水线（指令流水线）：以指令为单位，指构成处理机的各个功能部件的流水
       - 系统级流水（宏流水）：处理机之间的流水
     - 按流水线具有功能的多少：
       - 单功能流水线：只能完成一种固定功能的流水线，只能有一种功能
       - 多功能流水线：各段通过不同连接，以实现多种不同的功能
     - 在多功能流水线的基础上，按多功能流水线的各段是否允许同时用于不同功能连接流水：
       - 静态流水线：同一段时间内，多功能流水线的各个功能段只能按照一种固定的方式连接流水，实现一种固定的功能
       - 动态流水线：同一段时间内，多功能流水线的各段可以按照不同的方式连接，同时执行多种功能
     - 按流水线功能段之间有无反馈或前反馈回路分：
       - 线性流水线：各个段之间串行连接，无反馈也无跳跃，每个任务流经流水线中各个段均只有一次
       - 非线性流水线：除了有串行连接的通路，还有反馈回路或前馈回路，使任务流可多次经过流水线的某个段或越过某些段
       - 线性流水线能够用流水线连接图来唯一表示，非线性流水线必须用流水线连接图和流水线预约表等共同表示

2. **流水线处理机的主要性能：**:book:

   - 吞吐率（Throughput，TP）：

     - <u>是指流水线在单位时间内能流出的任务数或结果数，即完成的任务或输出的结果的数量</u>

     - 受限于流水线中最慢子过程经过的时间。流水线中最慢子过程称为瓶颈子过程

     - 消除瓶颈子过程的方法：

       - <u>瓶颈子过程再细分</u>
       - <u>瓶颈流水段重复设置</u>

     - 最大吞吐率：
       $$
       TP_{max}=\frac{1}{\max_{i=1}^{n}\Delta t_i}
       $$
       受限于瓶颈子过程

     - 实际吞吐率：
       $$
       TP=\frac{n}{m \Delta t_0 + (n-1) \Delta t_0}=\frac{1}{\Delta t_0 (1+\frac{m-1}{n})}=\frac{TP_{max}}{1+\frac{m-1}{n}}
       $$
       若流水线各段的执行时间均相等为 $\Delta t_0$，用 $m$ 个时钟周期输出第一个任务，其余 $n-1$ 个任务每隔 $\Delta t_0$ 输出一个任务

     - 若各段时间不等，实际吞吐率：
       $$
       TP=\frac{n}{\sum_{i=1}^{m}\Delta t_i +(n-1)\max_{i=1}^{m}\Delta t_i}
       $$

   - 加速比（Speedup Ratio，SR）：

     - <u>表示流水线方式相对非流水线顺序串行方式速度提高的比值</u>

     - 连续完成 $n$ 个任务需要 $nm\Delta t_0$ 的时间，因此加速比为：
       $$
       S_P=\frac{nm\Delta t_0}{m \Delta t_0 + (n-1) \Delta t_0}=\frac{m}{1+\frac{m-1}{n}}
       $$

     - 当 $n \gg m$ 时，这种情况下最大加速比 $S_{max}=m$，在线性流水线的各段执行时间均相等的情况下，流水线的最大加速比等于流水线的段数

     - 如果各段时间不等，则加速比为：
       $$
       S_P=\frac{n\sum_{i=1}^{m}\Delta t_i}{\sum_{i=1}^{m}\Delta t_i +(n-1)\max_{i=1}^{m}\Delta t_i}
       $$

   - 效率（Efficiency）：

     - <u>指流水线中的设备实际使用时间占整个运行时间之比，也称流水线设备的时间利用率。由于流水线存在建立时间和排空时间，在连续完成所有任务的时间里，各个段并不是满负荷工作的</u>

     - 若是线性流水线，且各段经过的时间相同，则各段的效率均相同：
       $$
       \eta_1=\eta_2=\dots=\eta_m=\frac{n \Delta t_0}{T}=\frac{n}{m+n-1}=\eta_0
       $$

     - 整个流水线的效率为：
       $$
       \eta=\frac{\sum_{i=1}^{m}\eta_i}{m}=\frac{m \cdot \eta_0}{m}=\frac{m \cdot n \Delta t_0}{m \cdot T}=\frac{n\cdot \Delta t_0}{T}=TP \cdot \Delta t_0
       $$

     - 当 $n \gg m$ 时，$\eta_{max}=1$；$\eta$ 同 $TP$ 成正比

     - 对于非线性流水线或线性流水线各段时间不等，只有画出实际工作的时空图才能求出吞吐率和效率：
       $$
       \eta=\frac{n \space 个任务实际占用的时间-空区}{m \space 个段总的时间-空区}=\frac{n \cdot \sum_{i=1}^{m}\Delta t_i}{m \cdot [\sum_{i=1}^{m}\Delta t_i +(n-1)\max_{i=1}^{m}\Delta t_i]}
       $$

3. **流水线调度：**:book:

### 向量的流水处理与向量流水处理机

1. **向量的流水处理：**
   - 横向处理方式：又称为水平处理方式，横向加工方式等。向量计算是按行的方式从左至右横向地进行
   - 纵向处理方式：又称为垂直处理方式，纵向加工方式等。向量计算是按列的方式自上而下纵向地进行
   - 纵横处理方式：又称为分组处理方式，纵横向加工方式等。横向处理和纵向处理相结合的方式

### 指令级高度并行的超级处理机

1. **超标量处理机：**

   - 超标量处理机采取设置 $m$ 条指令流水线同时并行工作，每隔 $\Delta t$ 可流出 $m$ 条指令。它是靠编译时，由编译程序来优化编排指令的执行顺序，将可并行的指令搭配成组，即重组（Reorganize），硬件不调整所执行指令的顺序，以利于实现

   - 单发射和多发射：

     - 单发射：每个周期只取一个指令，只译码一条指令，只执行一条指令，只写回一个运算结果；取指部件和译码部件各设置一套；可以只设置一个多功能操作部件，也可以设置多个独立的操作部件；操作部件中可以采用流水线结构，也可以不采用流水线结构；设计目标是每个时钟周期平均执行一条指 令，ILP 的期望值1，指令少时 ILP 小于 1
     - 多发射：每隔几本时钟周期同时取多条指令，同时译码多条指令，同时执行多条指令，同时写回多个运算结果；需要多个取指令部件，多个指令译码部件和多个写结果部件；设置多个指令执行部件，复杂的指令执行部件一般采用流水线结构；设计目标是每个时钟周期平均执行多条指令，ILP 的期望值大于1，实际情况下 ILP 介于1和多发射条数之间

   - 超标量处理机的性能：

     - 指令级并行度为 $(m,1)$ 的超标量处理机，执行 $N$ 条指令所用时间为：
       $$
       T(m,1)=(k+\frac{N-m}{m})\Delta t
       $$

     - 相较单流水线普通标量处理机的加速比为：
       $$
       S(m,1)=\frac{T(1,1)}{T(m,1)}=\frac{(k+N-1)\Delta t}{(k+\frac{N-m}{m})\Delta t}=\frac{m(k+N-1)}{mk+N-m}
       $$

     - 超标量处理机的理想最大加速比为：
       $$
       S(m,1)_{max}=m,N \rightarrow \infty
       $$

2. **超流水线处理机：**

   - 一台度为 $n$ 的超流水线处理机每隔 $\Delta t'$ 就流出一条指令，此时 $\Delta t'=\Delta t/n$

   - <u>一种定义是一个周期内能够分时发射多条指令的处理机称为超流水线处理机；另一种定义是将指令流水线有8个或更多功能段的流水线处理机称为超流水线处理机</u>

   - 提高处理机性能的不同方法：

     - 超标量处理机是通过增加硬件资源为代价来换取处理机性能的。重复设置执行部件，不止两个执行部件
     - 超流水线处理机则通过各硬件部分充分重叠工作来提高处理机性能。只需增加少量硬件，以更小的节拍工作

   - 超流水线处理机性能：

     - 指令并行度为 $(1,n)$ 的超流水线处理机，执行 $N$ 条指令所需的时间为：
       $$
       T(1,n)=(k+\frac{N-1}{n})\Delta t
       $$
   
     - 相较单流水线普通标量处理机的加速比为：
       $$
       S(1,n)=\frac{T(1,1)}{T(1,n)}=\frac{(k+N-1)\Delta t}{(k+\frac{N-1}{n})\Delta t}=\frac{n(k+N-1)}{nk+N-1}
       $$
   
     - 超流水线处理机的理想最大加速比为：
       $$
       S(1,n)_{max}=n,N \rightarrow \infty
       $$
   
3. **超标量超流水线处理机：**

   - 超标量超流水线处理机在一个时钟周期内分时发射指令 $n$ 次，每次同时发射指令 $m$ 条，每个时钟周期总共发射指令 $m \times n$ 条

   - 超标量超流水线处理机性能：

     - 指令级并行度为 $(m,n)$ 的超标量超流水线处理机，连续执行 $N$ 条指令所需要的时间为：
       $$
       T(m,n)=(k+\frac{N-m}{m \cdot n})\Delta t
       $$

     - 相较单流水线普通标量处理机的加速比为：
       $$
       S(m,n)=\frac{T(1,1)}{T(m,n)}=\frac{(k+N-1)\Delta t}{(k+\frac{N-m}{m \cdot n})\Delta t}=\frac{m \cdot n \cdot (k+N-1)}{m \cdot n \cdot k+N-m}
       $$

     - 超标量超流水线的理想最大加速比为：
       $$
       S(m,n)_{max}=m \cdot n,N \rightarrow \infty
       $$

4. **三种指令级并行处理机性能比较**

5. **超长指令字处理机：**

   - 超长指令字处理机将水平型微码和超标量处理两者结合
   - 在编译时，将多个能并行执行的不相关或无关的操作组合在一起，形成一条有多个操作码字段的超长指令字

## 并行处理机和互联网络

### 并行处理机原理

1. **并行处理机定义及特点：**
   - <u>并行处理机也称阵列处理机，有时也称 SIMD 计算机，它由多个 PE（Processing Element）按照一定方式互连，在同一个 CU（Control Unit）控制下，对各自的数据完成同一条指令规定的操作</u>
   - 从 CU 看，指令是串行执行的；从 PE 看，数据是并行处理的。按照弗林分类法，它属于操作系统级并行的 SIMD 计算机
   - 特点：
     - 速度快，而且潜力大
     - 模块性好，生产和维护方便
     - 可靠性高，容易实现容错和重构
     - 效率低（与流水线处理机、向量处理机等比较）。通常作为专用计算机，因此，在很大程度上依赖于并行算法。它依靠的是资源重复，而不是时间重叠
2. **阵列处理机的构形与特点：**
   - 阵列处理机的构形与特点：
     - 分布式存储器构形
     - 集中式共享存储器构形
   - 阵列处理机的特点：
     - 阵列处理机采用的是资源重复，利用的是并行性中的同时性，实现的是操作系统级的并行；而流水线处理机采用时间重叠，利用的是并行性中的并发性
     - 阵列处理机提高速度主要靠增多处理单元数，而向量流水线处理机主要靠缩短时钟周期数。阵列处理机比向量流水线处理机速度提高的潜力要大得多
     - 阵列处理机专用性强，灵活性差；流水线处理机通用性强，灵活性好
     - 阵列处理机使用简单规整的互连网络来连接处理单元，且其结构和并行算法有紧密联系
     - 阵列处理机的设备利用率可能没有多个单功能流水线部件高

### 阵列处理机的并行算法

1. **ILLIAC IV 的处理单元阵列结构**​ :book:
2. **阵列处理机的并行算法举例**

### 互连网络的基本概念

1. **互连网络的设计目标及互连函数：**

   - 互连网络的设计目标：

     - 结构要简单，以降低成本
     - 互连要灵活，以满足算法和应用的需要
     - 处理单元间信息传送的步数要尽可能少，以提高运算速度
     - 尽可能用规整单一的基本构件组合而成

   - 互连网络的表示方法：

     - 互连函数表示法
     - 图形表示法
     - 输入输出对应表示法

   - 互连网络的特性：

     - 互连网络通畅是由有向边或无向边连接的有限个节点组成的
     - 网络规模：网络中节点的个数
     - 节点度：与节点相连的边数，包括入度和出度
     - 距离：两个节点之间相连最小边数
     - 网络直径：网络中任意两个节点间距离的最大值
     - 节点间的线长：两个节点间连线的长度，用米、千米等表示
     - 对称性：从任何节点看到拓扑结构都是一样的网络称为对称网络。对称网络比较容易实现，编程也较容易
     - 等分宽度

   - 互连网络的传输性能参数：

     - 频带宽度（Bandwidth）：互连网络传输信息的最大速率，单位是 Mb/s 而不是 MB/s

     - 传输时间（Transmission Time）：消息通过网络的时间，等于消息长度除以频带宽度

     - 飞行时间（Time of Flight）：消息的第一位信息到达接收方所花费的时间，它包括由于网络转发和其他硬件所引起的时延

     - 传输时延（Transport Latency）：等于传输时间与飞行时间之和，是消息在互连网络上花费的时间

     - 发送方开销（Sender Overhead）：处理器把消息放到互连网络的时间

     - 接收方开销（Receiver Overhead）：处理器把消息从互连网络取出来的时间

     - 一个消息的总时延可以用下面的公式表示：
       $$
       总时延=发送方开销+飞行时间+消息长度/频带宽度+接收方开销
       $$
       其中 $消息长度/频带宽度$ 就是传输时间

2. **设计互连网络时应考虑的问题：**

   - 操作方式
   - 控制策略
   - 交换方式
   - 网络拓扑

### 互连网络的种类

1. **静态互连网络：**

   - 静态互连网络在各节点之间有固定的连接通路，在运行过程中不能改变网络结构
   - 环形网（弦环网、循环移数网络）
   - 树状（二叉树网、二叉胖树网）和星形网
   - 网格状网

2. **循环互连网络**

3. **基本的单极互连网络：**

   - 立方体单级网络：$N$ 个节点的立方体单级网络共有 $n=log_2N$ 种互连函数：
     $$
     Cube_i(P_{n-1} \dots P_i \dots P_1P_0)=P_{n-1} \dots \overline{P_i} \dots P_1P_0
     $$
     单级立方体网络的最大距离是 $n$，即最多经过 $n$ 次传送就可以实现任意一对入端和出端相连；当维数 $n>3$ 时，称之为超立方体网络

   - PM2I 单级互连网络：
     $$
     PM2_{+i}(j)=j+2^i \mod{N} \\
     PM2_{-i}(j)=j-2^i \mod{N} \\
     PM2_{+(n-1)}(j)=PM2_{-(n-1)}(j) \\
     0 \le i \le n-1,0 \le j \le N-1,n=\log_2N
     $$
     PM2I 单级网络的最大距离为 $\lceil n/2 \rceil$

   - 混洗交换单级互连网络：
     $$
     Shuffle(P_{n-1}P_{n-2} \dots P_1P_0)=P_{n-2}P_{n-3} \dots P_1P_{n-1}
     $$
     在混洗交换网扩中，最大距离为 $2n-1$。最远的两个 PE（编号为全0和全1）连接需要经过 $n$ 次交换和 $n-1$ 次混洗

   - 蝶形单级网络：
     $$
     Butterfly(P_{n-1}P_{n-2} \dots P_1P_0)=P_0P_{n-2} \dots P_1P_{n-1}
     $$

4. **多级互连网络：**

   - 决定多级互连网络的主要因素有三个：
     - 交换开关
     - 交换开关之间的拓扑连接
     - 对交换开关的控制方式
   - 多级立方体网络：有 STARAN 网络和间接二进制 n 方体网络

5. **全排列网络**

## 多处理机与多计算机

### 多处理机概念

1. **多处理机定义：**
   - 定义：
     - <u>由两台及以上处理机组成的计算机系统</u>
     - <u>各处理机有自己的控制部件、局部存储器，能执行各自的程序，可以共享公共主存和所有外设</u>
     - <u>各处理机通过某种形式互连，相互通信</u>
     - <u>实现作业、任务、指令、数据等各个级别的并行</u>
     - <u>属于弗林分类法中的 MIMD</u>
   - 优点：
     - <u>提高性能</u>
     - <u>提高可靠性</u>
     - <u>减少机器功耗</u>
     - <u>提高效费比和可扩展性</u>
2. **多处理机分类：**
   - 根据实现并行性技术途径不同，可以分为：
     - 同构型多处理机：基于资源重复；由大量同类型或是功能相同的处理机组成；并行处理任务
     - 异构型多处理机：基于时间重叠；由负责不同功能的多个专用处理机组成；重叠处理任务
     - 分布式多处理机：基于资源共享；由类型/功能相同/不同的处理机组成；多个处理机协作完成任务的处理
   - 根据物理连接的紧密程度和交叉作用能力的强弱，可以分为：
     - 紧耦合处理机：也称为直接耦合系统或多处理机。各处理机通过公共硬件资源（例如共享存储器和 I/O 系统）实现机间通信和同步
     - 松耦合处理机：也称为间接耦合系统或多计算机。多个处理机之间通过通道、通信线路或通信网络、消息传递系统实现处理机之间的通信和同步
3. **多处理机特点和主要技术问题：**
   - <u>多处理机实现的并行性中的并发性</u>
   - 多处理机的特点：
     - 结构灵活性
     - 程序并行性：多处理机并行性主要体现在指令外部，即表现在多个任务之间
     - 并行任务派生：可并行执行任务的识别、派生与分配
     - 进程同步：解决数据相关和控制依赖问题
     - 资源分配和调度：动态分配资源和调度任务，以获得更好性能和更高效率
   - 多处理机的主要技术问题：
     - 结构灵活性和通用性：应适应多种算法，同时避免对共享资源的访问冲突
     - 进程之间的通信方法：进程之间可以通过共享存储器通信，也可以通过消息传输机制通信
     - 运行模型：可以实现数据并行，也可以实现处理并行
     - 并行性的表达：可以由编译程序自动发现并行性，也可以利用支持并行程序设计的语言
     - 算法开发：并行性明显的程序很容易实现并行，因此需要开发或设计易于将作业分解为不同的并行任务，进而实现并行处理算法

### 多处理机结构

从存储器的分布和使用上看，多处理机分为共享存储器和分布式存储器两种结构

1. **共享存储器结构：**

   - <u>定义：各处理机通过互连网络共享存储器和 I/O 设备，并通过共享存储器相互联系；任何一个处理机对存储单元的任何修改对其它处理机都是可见的</u>

   - 结构图：

     <img src="/Users/hyperzsb/Library/Application Support/typora-user-images/image-20210609105332368.png" alt="image-20210609105332368" style="zoom: 45%;" />

   - 特点：

     - 各处理机共享存储空间，并通过对共享存储器的读写实现相互通信
     - 对存储单元的任何修改对其他处理机都是可见的
     - 存储器访问延迟低，但扩展性差

   - 根据访存时间是否相同，共享存储器结构又细分为三种结构，均衡存储器访问（[UMA](#UMA)）结构、非均衡存储器访问（[NUMA](#NUMA)）结构和仅用 Cache 存储器（[COMA](COMA)）结构

   - 均衡存储器访问结构：

     - 均衡存储器访问（<span id="UMA">Uniform Memory Access，UMA</span>）结构也被称为集中式共享存储器（Centralized Shared-Memroy）结构或对称多处理机（<span id="SMP">Symmetric Multiprocessors，SMP</span>）

     - 各处理机通过互连网络共享一个主存储器和 I/O 设备，对存储器不同部分的访问时间、访问功能相同

     - 均衡存储器访问多处理机的互连网络可以是总线、交叉开关或是多级交换网络。大多数的对称多处理机采用总线连接

     - 优点：

       - 性能提高
       - 高可用性
       - 增量式增长
       - 可扩展性好
       - 透明

     - 缺点：

       - 所有处理机对共享存储器的访问都要经过互连网络，当规模较大时，访问延迟较大。因此通常增设大容量本地 Cache

     - 结构图：

       <img src="/Users/hyperzsb/Library/Application Support/typora-user-images/image-20210609145655488.png" alt="image-20210609145655488" style="zoom: 40%;" />

   - 非均衡存储器访问结构：

     - 非均衡存储器访问（<span id="NUMA">Non-Uniform Memory Access，NUMA</span>）结构也称为分布式共享存储器（<span id="DSM">Distributed Shared-Memory，DSM</span>）结构或可缩放共享存储器（<span id="SSM">Scalable Shared-Memory，SSM</span>）结构

     - 在这种结构中，不设置物理上的共享存储器，而是将分布于各个处理机的存储器统一编址，形成一个逻辑上的统一存储空间，该空间被所有处理机共享访问

     - 各处理机拥有自己的本地存储器，可以独立工作；各处理机借助互连网络、通过消息传递机制相互通信；允许各处理机拥有自己独立结构，甚至可以是 SMP

     - 优点：

       - 比SMP扩展性好，并行程度更高，性能更好
       - 采用与SMP相同的编程模型，为SMP编写的程序仅需少量修改即可移植运行
       - 每个处理机都可以访问较大的存储空间，因此可以更高效地运行大程序
       - 实现数据共享时不需要移动数据
       - 传递包含指针的数据结构比较容易
       - 系统构建成本较低，利用成熟技术搭建系统

     - 缺点：

       - 如果过多地访问远程存储器，则性能会下降
       - 对存储器的访问不透明，需要处理分页（例如哪个页面在哪个存储器中）、进程分配等，对软件设计要求较高

     - 层次式机群模型结构图：

       <img src="/Users/hyperzsb/Library/Application Support/typora-user-images/image-20210609151236937.png" alt="image-20210609151236937" style="zoom:40%;" />

     - 共享本地存储器模型结构图：

       <img src="/Users/hyperzsb/Library/Application Support/typora-user-images/image-20210609151351798.png" alt="image-20210609151351798" style="zoom:45%;" />

   - ccNUMA：

     - 高速缓存一致性非均匀存储访问（<span id="ccNUMA">Cache-coherent Non-Uniform Memory Access，ccNUMA</span>）
     - 在 NUMA 多处理机中，逻辑上共享的存储器在物理上是分布的。如果各处理机 Cache 内容一致，则将这种 NUMA 称为 ccNUMA
     - 绝大多数商用 ccNUMA 多处理机系统使用基于目录的高速缓存一致性协议

   - 仅用 Cache 存储器结构：

     - 仅用高速缓存存储器（或全高速缓存存储结构）（<span id="COMA">Cache-Only Memory Architecture，COMA</span>）

     - 是 NUMA 的一个特例，只是将 NUMA 中的分布存储器换成了 Cache

     - 各处理机结点上没有主存储器，没有存储层次结构，仅有 Cache；所有的高速缓存构成了全局地址空间，全部 Cache组成了全局虚拟地址空间

     - 对远程Cache的访问通过分布式Cache目录进行

     - 结构图：

       <img src="/Users/hyperzsb/Library/Application Support/typora-user-images/image-20210609152816856.png" alt="image-20210609152816856" style="zoom:40%;" />

2. **分布式存储器结构：**

   - 也被称为非远程存储访问 (<span id="NoRMA">No-Remote Memory Access，NoRMA</span>) 模型

   - <u>各处理机拥有自己的本地存储器，在本地操作系统控制下独立工作</u>

   - <u>各处理机的本地存储器是私有的，不能被其他处理机访问</u>

   - <u>各处理机借助互连网络、通过消息传递机制相互通信，实现数据共享</u>

   - 大规模并行处理机（MPP）、机群（Cluster）等采用了这种结构

   - 特点：

     - 各处理机拥有自己的本地存储器，可以独立工作，访问本地存储器速度快
     - 各处理机的本地存储器不能被其他处理器访问
     - 各处理机借助互连网络，通过消息传递机制相互通信
     - 结构灵活，扩展性极好
     - 任务传输以及任务分配算法复杂，通常要设计专有算法
     - 处理机之间的访问延迟较大
     - 需要高带宽的互联

   - 结构图：

     <img src="/Users/hyperzsb/Library/Application Support/typora-user-images/image-20210609155825998.png" alt="image-20210609155825998" style="zoom:45%;" />

3. **大规模并行处理机：**

   - 大规模并行处理机（Massively Parallel Processor，MPP）

   - 由几百或几千台高性能、低成本处理机组成的大规模并行计算机系统

   - <u>每个处理机都有自己的私有资源，如内存、网络接口等；每个处理机能直接访问的只有本地存储器，但不能直接访问其它处理机的存储器</u>

   - <u>处理机之间以定制的高带宽、低延迟的高速互连网络互连</u>

   - MPP 系统大多采用分布式存储结构。所有存储器在物理上是分布的，而且都是私有的。每个处理机能直接访问的只有本地存储s器，不能直接访问其它处理机的存储器

   - 超算采用该架构

   - 特点：

     - 处理结点采用商用处理机
     - 系统中有物理上的分布式存储器
     - 采用高通信带宽和低延迟的互连网络（专门设计和定制的）
     - 能扩放至成百上千乃至上万个处理机
     - 它是一种异步的 MIMD 机器

   - 结构图：

     <img src="/Users/hyperzsb/Library/Application Support/typora-user-images/image-20210609160415419.png" alt="image-20210609160415419" style="zoom:40%;" />

4. **机群：**

   - 也称为集群（Cluster of Workstations，COW 或 Network of Workstations，NOW）
   - 通过一组松散耦合的计算机软件和硬件连接起来，高度紧密地协作完成计算工作的计算机系统

### 多核处理器

多核（Multi-core）处理器也称为片上多处理机（Chip Multi-Processors，CMP）或片上多处理机系统（Multi-Processor System-on-Chip，MPSoC），是多处理机的一种特殊形式。

1. **多核处理器定义与结构：**

   - 多核处理器定义：

     - 多核处理器是指在一枚处理器中集成两个或多个独立处理单元（成为核）组成的处理器
     - 多核处理器中的每个核可以完全独立地完成各自的工作
     - 多核处理器的九大关键技术：
       - 核结构研究
       - 程序执行模型
       - Cache 设计
       - 核间通信技术
       - 总线设计
       - 操作系统设计
       - 低功耗设计
       - 存储器墙
       - 可靠性及安全性设计

   - 多核处理器结构：

     - 多核处理器结构的设计主要考虑以下因素：

       - 同构还是异构
       - 核的数量
       - 存储器或 Cache 的设置及访问
       - 核间通信技术：当前的多核处理器典型采用 SMP，通过 Cache 层次访问共享存储器

     - 四种多核处理器结构图：

       - L1 Cache 专用，L2 Cache 在片外
       - L1 和 L2 Cache 均专用，均在片内
       - L1 Cache 专用，L2 Cache 共享，均在片内
       - L1 和 L2 Cache 均专用，L3 Cache 共享，均在片内

       <img src="/Users/hyperzsb/Library/Application Support/typora-user-images/image-20210609162931414.png" alt="image-20210609162931414" style="zoom:40%;" />

       <img src="/Users/hyperzsb/Library/Application Support/typora-user-images/image-20210609163008201.png" alt="image-20210609163008201" style="zoom:40%;" />

### 多处理机的多 Cache 一致性

1. **存储器一致性定义：**
   - <u>如果一道程序的任何运行结果都与按假定序列执行的结果一样，则称多处理机存储器是一致性的。存储器一致性隐含以下两点：</u>
     - <u>写传播（Write Propagation）：一个处理器对一个位置所写入的值，最终对其他处理器是可见的</u>
     - <u>写串行化（Write Serialization）：对同一个位置的所有写操作（来自同一个或不同处理器）应该能串行化，所有的处理器以相同的次序看到所有这些写操作，即任意两个处理器对同一个单元的两次写，从所有处理器看来顺序都应是相同的</u>
2. **多 Cache 一致性问题的产生：**
   - 导致多处理机多 Cache 不一致问题的原因有3个：
     - 共享可写数据引起的不一致
     - 进程迁移引起的不一致
     - I/O 传输引起的不一致
   - 上述三个问题中，不论采用写直达法还是写回法，在多处理机中都可能引起 Cache 不一致问题
3. **多 Cache 一致性问题解决方法：**
   - 基于硬件的方法：
     - 基于硬件的方法通常称为 Cache 一致性协议，即维护多处理机 Cache 一致性的协议
     - 监听协议（Snoopy Protocol）：
       - 将维护 Cache 一致性的责任分散到多处理中的所有 Cache 控制器。Cache 必须识别其缓存的数据何时被其他 Cache 共享。如果在共享数据上执行了更新操作，则必须通过广播机制（例如总线）将该更新通告给所有其他 Cache。每个 Cache 控制器都可以监听网络看是否有广播通知并进行相应操作
       - 有两种保持 Cache 一致性的方法：写无效（Write-Invalidate）和写更新（Write-Update）:book:
       - 每当 Cache 失效或更新数据时，监听协议都需要与所有 Cache 通信。不需要设置存储 Cacha 状态的集中式数据结构、透明、实现成本低是监听协议的主要优点，但广播效率不高，同时影响了其可扩展性
     - 基于目录的协议（Directory-Based Protocol）：
       - 将数据的修改只通知那些含有被修改数据副本的处理机。为此，设置了一个称为 Cache 目录的数据结构，记载申请了某一数据结构的所有处理机，当数据被更新时，就根据目录的记载，向所有其 Cache 中包含该数据的处理机点对点地发送无效信息或更新后的数据
       - Cache 目录的存放方式有：集中式和分布式
       - 目录也有多种形式：全映射目录、有限目录
   - 基于软件的方法：
     - 依靠编译和操作系统解决一致性问题
     - 缺点：编译时的软件做出的决定通常比较保守，因此导致 Cache 利用率下降

### 多处理机的机间互联形式

- 总线型
- 环形
- 交叉开关
- 多级交叉开关
- 多端口存储器

### 程序并行性

1. **并行算法：**
   - 用多台处理机联合求解问题的方法和步骤
   - 并行算法与串行算法最大的不同在于，并行算法不仅要考虑问题本身，而且还要考虑所使用的并行模型，网络连接等
   - 根据运算的基本对象的不同分为：
     - 数值并行算法（数值计算）
     - 非数值并行算法（符号计算）
   - 根据进程之间的依赖关系分为：
     - 同步并行算法（步调一致）
     - 异步并行算法（步调、进展互不相同）
     - 纯并行算法（各部分之间没有关系）
   - 根据并行计算任务的大小分为：并行的粒度越小，就有可能开发更多的并行性，提高并行度，但是通信次数和通信量就增加很多
     - 粗粒度并行
     - 细粒度并行
     - 中粒度并行
   - 并行算法还可以分为：
     - 多机并行
     - 多线程并行
   - 并行算法的评价
2. **程序段间的相关性分析：**
   - 数据相关：“先写后读” ，可以顺序串行，但不能并行
   - 数据反相关：“先读后写” ，可以顺序串行，不能交换串行，在特殊情况下可以并行
   - 数据输出相关：“写−写” ，可以顺序串行，不能交换串行，在特殊情况下可以并行
   - 相互交换：条件语句
   - 无相关或仅有源数据相关：同时具有“先写后读”和“先读后写”相关，以交换数据为目的
3. **并行程序设计语言**

### 多处理机的性能 :memo:

1. **基本模型：**
2. **N 台处理机系统的基本模型：**

### 多处理机操作系统

1. **主从型操作系统：**
   - 主从型操作系统由一台主处理机记录、控制其他从处理机的状态，并分配任务给从处理机，采取集中控制
   - 主处理机一旦出故障，容易使系统瘫痪
   - 主从型适合于工作负荷固定，从处理机能力明显低于主处理机，或由功能相差很大的处理机组成的异构型多处理机系统
2. **各自独立型操作系统：**
   - 也称为独立监督式操作系统。各自独立型操作系统将控制功能分散到多台处理机上，由它们共同来完成。在这种类型中，每一个处理机均有各自的管理程序（核心）
   - 某个处理机发生故障，不会引起整个系统瘫痪
   - 各自独立型适用于松耦合多处理机系统
3. **浮动型操作系统：**
   - 浮动型操作系统是介于主从型和各自独立型之间的一种折中方式
   - 适用于紧耦合的同构型多处理机系统

## 题目

- 计算机系统的主要软、硬件交界面特性包括（指令系统）、（数据表示）、（存储系统）、（中断系统）和（I/O 系统）

- 输入输出系统的发展历经三个阶段，对应三种方式，即程序控制 I/O（包括全软件的、程序查询的、中断驱动的）、（DMA）和（I/O 处理机）
- 寻址有面向（寄存器）、（堆栈）和（主存）等寻址方式
- 支持动态地址再定位的寻址方式是（基址寻址）
- Cache 存储器是（存储体系）
- 评价存储器性能的基本要求是（大容量）、（高速度）和（低价格）
- 评价虚拟存储器所用替换算法的好坏，主要是看主存（命中率）的高低，其次看算法是否易于（实现），以及所需的辅助（软件、硬件）的多少
- 阵列流水线是（二维以上流水线）
- 从单机向多机发展的三条途径：（时间重叠）、（资源重复）和（资源共享）
- SIMD 互连网络是连接（多个处理机）的网络
- 并行多处理机系统具有多个相同结构的处理机
- 并行处理机与流水线处理机相比，通用性（差），灵活性（差）
- 目前市面上的个人电脑的升级换代主要选用的技术是微处理机技术（是对的）
- Flynn 分类法可以对所有计算机系统进行分类（是错的）
- 目前绝大多数计算机系统都采用存储器映射的 I/O（是对的）
- 块的大小、组的大小及 Cache 容量增大时一定能提高 Cache 命中率（是错的）
- 页式虚拟存储器中某道程序的主存容量一定时，页面容量越大，主存命中率越高（是错的）

